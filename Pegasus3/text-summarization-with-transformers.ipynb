{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":44284,"sourceType":"datasetVersion","datasetId":33526}],"dockerImageVersionId":30097,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Acknowledgements\n\nThe code for the transformer model is take from  this tutorial https://www.tensorflow.org/text/tutorials/transformer","metadata":{}},{"cell_type":"markdown","source":"# Installing Packages needed and Importing Libraries","metadata":{}},{"cell_type":"code","source":"!pip install openpyxl  --quiet","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:12.510297Z","iopub.execute_input":"2024-06-17T03:57:12.510662Z","iopub.status.idle":"2024-06-17T03:57:19.539406Z","shell.execute_reply.started":"2024-06-17T03:57:12.510630Z","shell.execute_reply":"2024-06-17T03:57:19.538362Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom collections import defaultdict\nimport string\nimport tensorflow as tf\nimport re\nimport os\nimport time\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:19.541296Z","iopub.execute_input":"2024-06-17T03:57:19.541654Z","iopub.status.idle":"2024-06-17T03:57:19.548364Z","shell.execute_reply.started":"2024-06-17T03:57:19.541618Z","shell.execute_reply":"2024-06-17T03:57:19.547473Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ENCODER_LEN = 100\nDECODER_LEN = 20\nBATCH_SIZE = 64\nBUFFER_SIZE = BATCH_SIZE*8","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:19.550536Z","iopub.execute_input":"2024-06-17T03:57:19.550937Z","iopub.status.idle":"2024-06-17T03:57:19.558678Z","shell.execute_reply.started":"2024-06-17T03:57:19.550851Z","shell.execute_reply":"2024-06-17T03:57:19.557874Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Dataset\n\nAfter creating the dataframe we apply Start of Sentence(<SOS>) and End of Sentence(<EOS>) tokens. \nThese sentences are then tokenized and padded to fix length.","metadata":{}},{"cell_type":"code","source":"news = pd.read_excel(\"../input/inshorts-news-data/Inshorts Cleaned Data.xlsx\",engine = 'openpyxl')\nnews.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)\nnews.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:19.560053Z","iopub.execute_input":"2024-06-17T03:57:19.560324Z","iopub.status.idle":"2024-06-17T03:57:29.814304Z","shell.execute_reply.started":"2024-06-17T03:57:19.560282Z","shell.execute_reply":"2024-06-17T03:57:29.813462Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            Headline  \\\n0  4 ex-bank officials booked for cheating bank o...   \n1     Supreme Court to go paperless in 6 months: CJI   \n2  At least 3 killed, 30 injured in blast in Sylh...   \n3  Why has Reliance been barred from trading in f...   \n4  Was stopped from entering my own studio at Tim...   \n\n                                               Short  \n0  The CBI on Saturday booked four former officia...  \n1  Chief Justice JS Khehar has said the Supreme C...  \n2  At least three people were killed, including a...  \n3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n4  TV news anchor Arnab Goswami has said he was t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Headline</th>\n      <th>Short</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4 ex-bank officials booked for cheating bank o...</td>\n      <td>The CBI on Saturday booked four former officia...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Supreme Court to go paperless in 6 months: CJI</td>\n      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n      <td>At least three people were killed, including a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Why has Reliance been barred from trading in f...</td>\n      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Was stopped from entering my own studio at Tim...</td>\n      <td>TV news anchor Arnab Goswami has said he was t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"article = news['Short']\nsummary = news['Headline']\narticle = article.apply(lambda x: '<SOS> ' + x + ' <EOS>')\nsummary = summary.apply(lambda x: '<SOS> ' + x + ' <EOS>')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:29.815659Z","iopub.execute_input":"2024-06-17T03:57:29.816046Z","iopub.status.idle":"2024-06-17T03:57:29.902598Z","shell.execute_reply.started":"2024-06-17T03:57:29.816007Z","shell.execute_reply":"2024-06-17T03:57:29.901649Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def preprocess(text):\n    text = re.sub(r\"&.[1-9]+;\",\" \",text)\n    return text\narticle = article.apply(lambda x: preprocess(x))\nsummary = summary.apply(lambda x: preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:29.903885Z","iopub.execute_input":"2024-06-17T03:57:29.904263Z","iopub.status.idle":"2024-06-17T03:57:30.212696Z","shell.execute_reply.started":"2024-06-17T03:57:29.904223Z","shell.execute_reply":"2024-06-17T03:57:30.211819Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\noov_token = '<unk>'\narticle_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\nsummary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\narticle_tokenizer.fit_on_texts(article)\nsummary_tokenizer.fit_on_texts(summary)\ninputs = article_tokenizer.texts_to_sequences(article)\ntargets = summary_tokenizer.texts_to_sequences(summary)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:30.213798Z","iopub.execute_input":"2024-06-17T03:57:30.214087Z","iopub.status.idle":"2024-06-17T03:57:39.588646Z","shell.execute_reply.started":"2024-06-17T03:57:30.214060Z","shell.execute_reply":"2024-06-17T03:57:39.587660Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ENCODER_VOCAB = len(article_tokenizer.word_index) + 1\nDECODER_VOCAB = len(summary_tokenizer.word_index) + 1\nprint(ENCODER_VOCAB, DECODER_VOCAB)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:39.591342Z","iopub.execute_input":"2024-06-17T03:57:39.591661Z","iopub.status.idle":"2024-06-17T03:57:39.597190Z","shell.execute_reply.started":"2024-06-17T03:57:39.591629Z","shell.execute_reply":"2024-06-17T03:57:39.596192Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"76362 29661\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\ntargets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\ninputs = tf.cast(inputs, dtype=tf.int64)\ntargets = tf.cast(targets, dtype=tf.int64)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:39.599118Z","iopub.execute_input":"2024-06-17T03:57:39.599488Z","iopub.status.idle":"2024-06-17T03:57:43.161438Z","shell.execute_reply.started":"2024-06-17T03:57:39.599455Z","shell.execute_reply":"2024-06-17T03:57:43.160613Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.162668Z","iopub.execute_input":"2024-06-17T03:57:43.163141Z","iopub.status.idle":"2024-06-17T03:57:43.224193Z","shell.execute_reply.started":"2024-06-17T03:57:43.163096Z","shell.execute_reply":"2024-06-17T03:57:43.223398Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Transformer Model\n\nThe next several blocks of code contain the vanilla Transformer model.\n\nIf you want to know about what they are and how they work I suggest this video: https://www.youtube.com/watch?v=4Bdc55j80l8\n\nIt does an excellent job of giving an overview about them and helped me in understanding them.","metadata":{}},{"cell_type":"code","source":"def get_angles(position, i, d_model):\n    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n    return position * angle_rates\n\ndef positional_encoding(position, d_model):\n    angle_rads = get_angles(\n        np.arange(position)[:, np.newaxis],\n        np.arange(d_model)[np.newaxis, :],\n        d_model\n    )\n\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    pos_encoding = angle_rads[np.newaxis, ...]\n\n    return tf.cast(pos_encoding, dtype=tf.float32)\n\ndef create_padding_mask(seq):\n    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n    return seq[:, tf.newaxis, tf.newaxis, :]\n\ndef create_look_ahead_mask(size):\n    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n    return mask\n\ndef scaled_dot_product_attention(q, k, v, mask):\n    matmul_qk = tf.matmul(q, k, transpose_b=True)\n\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n    if mask is not None:\n        scaled_attention_logits += (mask * -1e9)  \n\n    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n\n    output = tf.matmul(attention_weights, v)\n    return output, attention_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.225636Z","iopub.execute_input":"2024-06-17T03:57:43.226026Z","iopub.status.idle":"2024-06-17T03:57:43.238366Z","shell.execute_reply.started":"2024-06-17T03:57:43.225985Z","shell.execute_reply":"2024-06-17T03:57:43.237444Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n\n        assert d_model % self.num_heads == 0\n\n        self.depth = d_model // self.num_heads\n\n        self.wq = tf.keras.layers.Dense(d_model)\n        self.wk = tf.keras.layers.Dense(d_model)\n        self.wv = tf.keras.layers.Dense(d_model)\n\n        self.dense = tf.keras.layers.Dense(d_model)\n        \n    def split_heads(self, x, batch_size):\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n    \n    def call(self, v, k, q, mask):\n        batch_size = tf.shape(q)[0]\n\n        q = self.wq(q)\n        k = self.wk(k)\n        v = self.wv(v)\n\n        q = self.split_heads(q, batch_size)\n        k = self.split_heads(k, batch_size)\n        v = self.split_heads(v, batch_size)\n\n        scaled_attention, attention_weights = scaled_dot_product_attention(\n            q, k, v, mask)\n\n        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n        \n        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n        output = self.dense(concat_attention)\n            \n        return output, attention_weights\n    \ndef point_wise_feed_forward_network(d_model, dff):\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(dff, activation='relu'),\n        tf.keras.layers.Dense(d_model)\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.239779Z","iopub.execute_input":"2024-06-17T03:57:43.240142Z","iopub.status.idle":"2024-06-17T03:57:43.255273Z","shell.execute_reply.started":"2024-06-17T03:57:43.240100Z","shell.execute_reply":"2024-06-17T03:57:43.254463Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=0.1):\n        super(EncoderLayer, self).__init__()\n\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n    \n    def call(self, x, training, mask):\n        attn_output, _ = self.mha(x, x, x, mask)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(x + attn_output)\n\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        out2 = self.layernorm2(out1 + ffn_output)\n\n        return out2","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.256343Z","iopub.execute_input":"2024-06-17T03:57:43.256615Z","iopub.status.idle":"2024-06-17T03:57:43.269354Z","shell.execute_reply.started":"2024-06-17T03:57:43.256589Z","shell.execute_reply":"2024-06-17T03:57:43.268678Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=0.1):\n        super(DecoderLayer, self).__init__()\n\n        self.mha1 = MultiHeadAttention(d_model, num_heads)\n        self.mha2 = MultiHeadAttention(d_model, num_heads)\n\n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n        self.dropout3 = tf.keras.layers.Dropout(rate)\n    \n    \n    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n        attn1 = self.dropout1(attn1, training=training)\n        out1 = self.layernorm1(attn1 + x)\n\n        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n        attn2 = self.dropout2(attn2, training=training)\n        out2 = self.layernorm2(attn2 + out1)\n\n        ffn_output = self.ffn(out2)\n        ffn_output = self.dropout3(ffn_output, training=training)\n        out3 = self.layernorm3(ffn_output + out2)\n\n        return out3, attn_weights_block1, attn_weights_block2","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.270545Z","iopub.execute_input":"2024-06-17T03:57:43.270851Z","iopub.status.idle":"2024-06-17T03:57:43.283594Z","shell.execute_reply.started":"2024-06-17T03:57:43.270817Z","shell.execute_reply":"2024-06-17T03:57:43.282769Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n        super(Encoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n\n        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n\n        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n\n        self.dropout = tf.keras.layers.Dropout(rate)\n        \n    def call(self, x, training, mask):\n        seq_len = tf.shape(x)[1]\n\n        x = self.embedding(x)\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n\n        x = self.dropout(x, training=training)\n    \n        for i in range(self.num_layers):\n            x = self.enc_layers[i](x, training, mask)\n    \n        return x\n    \nclass Decoder(tf.keras.layers.Layer):\n        \n    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n        super(Decoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n\n        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n\n        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n        self.dropout = tf.keras.layers.Dropout(rate)\n    \n    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n        seq_len = tf.shape(x)[1]\n        attention_weights = {}\n\n        x = self.embedding(x)\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n\n        x = self.dropout(x, training=training)\n\n        for i in range(self.num_layers):\n            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n\n            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n    \n        return x, attention_weights\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.284801Z","iopub.execute_input":"2024-06-17T03:57:43.285094Z","iopub.status.idle":"2024-06-17T03:57:43.302059Z","shell.execute_reply.started":"2024-06-17T03:57:43.285056Z","shell.execute_reply":"2024-06-17T03:57:43.301176Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n        super(Transformer, self).__init__()\n\n        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n\n        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n\n        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n    \n    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n        enc_output = self.encoder(inp, training, enc_padding_mask)\n\n        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n\n        final_output = self.final_layer(dec_output)\n\n        return final_output, attention_weights","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.303201Z","iopub.execute_input":"2024-06-17T03:57:43.303488Z","iopub.status.idle":"2024-06-17T03:57:43.314974Z","shell.execute_reply.started":"2024-06-17T03:57:43.303460Z","shell.execute_reply":"2024-06-17T03:57:43.314179Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"num_layers = 3\nd_model = 128\ndff = 512\nnum_heads = 4\ndropout_rate = 0.2\nEPOCHS = 15","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.316167Z","iopub.execute_input":"2024-06-17T03:57:43.316550Z","iopub.status.idle":"2024-06-17T03:57:43.326644Z","shell.execute_reply.started":"2024-06-17T03:57:43.316514Z","shell.execute_reply":"2024-06-17T03:57:43.325927Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Custom Learning Rate","metadata":{}},{"cell_type":"code","source":"class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, d_model, warmup_steps=4000):\n        super(CustomSchedule, self).__init__()\n\n        self.d_model = d_model\n        self.d_model = tf.cast(self.d_model, tf.float32)\n\n        self.warmup_steps = warmup_steps\n    \n    def __call__(self, step):\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps ** -1.5)\n\n        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.327686Z","iopub.execute_input":"2024-06-17T03:57:43.327930Z","iopub.status.idle":"2024-06-17T03:57:43.337147Z","shell.execute_reply.started":"2024-06-17T03:57:43.327907Z","shell.execute_reply":"2024-06-17T03:57:43.336421Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"learning_rate = CustomSchedule(d_model)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.338111Z","iopub.execute_input":"2024-06-17T03:57:43.338444Z","iopub.status.idle":"2024-06-17T03:57:43.347049Z","shell.execute_reply.started":"2024-06-17T03:57:43.338412Z","shell.execute_reply":"2024-06-17T03:57:43.346243Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"temp_learning_rate_schedule = CustomSchedule(d_model)\n\nplt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\nplt.ylabel(\"Learning Rate\")\nplt.xlabel(\"Train Step\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.348128Z","iopub.execute_input":"2024-06-17T03:57:43.348403Z","iopub.status.idle":"2024-06-17T03:57:43.571253Z","shell.execute_reply.started":"2024-06-17T03:57:43.348366Z","shell.execute_reply":"2024-06-17T03:57:43.570439Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 0, 'Train Step')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# Custom Loss and Accuracy","metadata":{}},{"cell_type":"code","source":"loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n\n\ndef accuracy_function(real, pred):\n    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    accuracies = tf.math.logical_and(mask, accuracies)\n\n    accuracies = tf.cast(accuracies, dtype=tf.float32)\n    mask = tf.cast(mask, dtype=tf.float32)\n    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.572306Z","iopub.execute_input":"2024-06-17T03:57:43.572592Z","iopub.status.idle":"2024-06-17T03:57:43.580281Z","shell.execute_reply.started":"2024-06-17T03:57:43.572564Z","shell.execute_reply":"2024-06-17T03:57:43.579349Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.Mean(name='train_accuracy')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.581650Z","iopub.execute_input":"2024-06-17T03:57:43.582007Z","iopub.status.idle":"2024-06-17T03:57:43.611757Z","shell.execute_reply.started":"2024-06-17T03:57:43.581970Z","shell.execute_reply":"2024-06-17T03:57:43.610773Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"transformer = Transformer(\n    num_layers=num_layers,\n    d_model=d_model,\n    num_heads=num_heads,\n    dff=dff,\n    input_vocab_size=ENCODER_VOCAB,\n    target_vocab_size=DECODER_VOCAB,\n    pe_input=1000,\n    pe_target=1000,\n    rate=dropout_rate)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.615628Z","iopub.execute_input":"2024-06-17T03:57:43.615921Z","iopub.status.idle":"2024-06-17T03:57:43.720095Z","shell.execute_reply.started":"2024-06-17T03:57:43.615889Z","shell.execute_reply":"2024-06-17T03:57:43.719266Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def create_masks(inp, tar):\n    enc_padding_mask = create_padding_mask(inp)\n    dec_padding_mask = create_padding_mask(inp)\n\n    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n    dec_target_padding_mask = create_padding_mask(tar)\n    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n  \n    return enc_padding_mask, combined_mask, dec_padding_mask","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.721721Z","iopub.execute_input":"2024-06-17T03:57:43.722020Z","iopub.status.idle":"2024-06-17T03:57:43.726901Z","shell.execute_reply.started":"2024-06-17T03:57:43.721986Z","shell.execute_reply":"2024-06-17T03:57:43.725991Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"checkpoints\"\n\nckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n\nif ckpt_manager.latest_checkpoint:\n    ckpt.restore(ckpt_manager.latest_checkpoint)\n    print ('Latest checkpoint restored!!')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.728153Z","iopub.execute_input":"2024-06-17T03:57:43.728488Z","iopub.status.idle":"2024-06-17T03:57:43.739230Z","shell.execute_reply.started":"2024-06-17T03:57:43.728459Z","shell.execute_reply":"2024-06-17T03:57:43.738457Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(inp, tar):\n    tar_inp = tar[:, :-1]\n    tar_real = tar[:, 1:]\n\n    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n\n    with tf.GradientTape() as tape:\n        predictions, _ = transformer(\n            inp, tar_inp, \n            True, \n            enc_padding_mask, \n            combined_mask, \n            dec_padding_mask\n        )\n        loss = loss_function(tar_real, predictions)\n\n    gradients = tape.gradient(loss, transformer.trainable_variables)    \n    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n\n    train_loss(loss)\n    train_accuracy(accuracy_function(tar_real, predictions))","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.740259Z","iopub.execute_input":"2024-06-17T03:57:43.740551Z","iopub.status.idle":"2024-06-17T03:57:43.749870Z","shell.execute_reply.started":"2024-06-17T03:57:43.740525Z","shell.execute_reply":"2024-06-17T03:57:43.749139Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model","metadata":{}},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    start = time.time()\n\n    train_loss.reset_states()\n  \n    for (batch, (inp, tar)) in enumerate(dataset):\n        train_step(inp, tar)\n    \n        if batch % 100 == 0:\n            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n      \n    if (epoch + 1) % 5 == 0:\n        ckpt_save_path = ckpt_manager.save()\n        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n   \n    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))","metadata":{"execution":{"iopub.status.busy":"2024-06-17T03:57:43.750921Z","iopub.execute_input":"2024-06-17T03:57:43.751177Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1 Batch 0 Loss 10.3153 Accuracy 0.0000\nEpoch 1 Batch 100 Loss 10.2133 Accuracy 0.0468\nEpoch 1 Batch 200 Loss 9.9966 Accuracy 0.0707\nEpoch 1 Batch 300 Loss 9.6851 Accuracy 0.0792\nEpoch 1 Batch 400 Loss 9.3406 Accuracy 0.0844\nEpoch 1 Batch 500 Loss 9.0258 Accuracy 0.0885\nEpoch 1 Batch 600 Loss 8.7786 Accuracy 0.0929\nEpoch 1 Batch 700 Loss 8.5833 Accuracy 0.0989\nEpoch 1 Batch 800 Loss 8.4246 Accuracy 0.1039\nEpoch 1 Loss 8.3392 Accuracy 0.1069\nTime taken for 1 epoch: 145.26546096801758 secs\n\nEpoch 2 Batch 0 Loss 7.6275 Accuracy 0.1070\nEpoch 2 Batch 100 Loss 7.3668 Accuracy 0.1086\nEpoch 2 Batch 200 Loss 7.2813 Accuracy 0.1107\nEpoch 2 Batch 300 Loss 7.2018 Accuracy 0.1127\nEpoch 2 Batch 400 Loss 7.1538 Accuracy 0.1150\nEpoch 2 Batch 500 Loss 7.1025 Accuracy 0.1176\nEpoch 2 Batch 600 Loss 7.0473 Accuracy 0.1204\nEpoch 2 Batch 700 Loss 6.9870 Accuracy 0.1236\nEpoch 2 Batch 800 Loss 6.9225 Accuracy 0.1268\nEpoch 2 Loss 6.8807 Accuracy 0.1287\nTime taken for 1 epoch: 135.17393255233765 secs\n\nEpoch 3 Batch 0 Loss 6.9920 Accuracy 0.1287\nEpoch 3 Batch 100 Loss 6.6453 Accuracy 0.1297\nEpoch 3 Batch 200 Loss 6.5571 Accuracy 0.1312\nEpoch 3 Batch 300 Loss 6.4847 Accuracy 0.1327\nEpoch 3 Batch 400 Loss 6.4419 Accuracy 0.1345\nEpoch 3 Batch 500 Loss 6.3964 Accuracy 0.1367\nEpoch 3 Batch 600 Loss 6.3506 Accuracy 0.1392\nEpoch 3 Batch 700 Loss 6.2975 Accuracy 0.1419\nEpoch 3 Batch 800 Loss 6.2391 Accuracy 0.1448\nEpoch 3 Loss 6.2006 Accuracy 0.1466\nTime taken for 1 epoch: 135.4257893562317 secs\n\nEpoch 4 Batch 0 Loss 6.3415 Accuracy 0.1466\nEpoch 4 Batch 100 Loss 6.0976 Accuracy 0.1478\nEpoch 4 Batch 200 Loss 6.0101 Accuracy 0.1493\nEpoch 4 Batch 300 Loss 5.9338 Accuracy 0.1510\nEpoch 4 Batch 400 Loss 5.8957 Accuracy 0.1529\nEpoch 4 Batch 500 Loss 5.8493 Accuracy 0.1550\nEpoch 4 Batch 600 Loss 5.8061 Accuracy 0.1574\nEpoch 4 Batch 700 Loss 5.7540 Accuracy 0.1600\nEpoch 4 Batch 800 Loss 5.6960 Accuracy 0.1629\nEpoch 4 Loss 5.6602 Accuracy 0.1646\nTime taken for 1 epoch: 134.75139212608337 secs\n\nEpoch 5 Batch 0 Loss 6.3046 Accuracy 0.1646\nEpoch 5 Batch 100 Loss 5.6334 Accuracy 0.1659\nEpoch 5 Batch 200 Loss 5.5390 Accuracy 0.1675\nEpoch 5 Batch 300 Loss 5.4637 Accuracy 0.1694\nEpoch 5 Batch 400 Loss 5.4268 Accuracy 0.1712\nEpoch 5 Batch 500 Loss 5.3808 Accuracy 0.1734\nEpoch 5 Batch 600 Loss 5.3390 Accuracy 0.1757\nEpoch 5 Batch 700 Loss 5.2907 Accuracy 0.1783\nEpoch 5 Batch 800 Loss 5.2348 Accuracy 0.1811\nSaving checkpoint for epoch 5 at checkpoints/ckpt-1\nEpoch 5 Loss 5.2013 Accuracy 0.1828\nTime taken for 1 epoch: 135.59765529632568 secs\n\nEpoch 6 Batch 0 Loss 5.8736 Accuracy 0.1828\nEpoch 6 Batch 100 Loss 5.2181 Accuracy 0.1842\nEpoch 6 Batch 200 Loss 5.1240 Accuracy 0.1860\nEpoch 6 Batch 300 Loss 5.0471 Accuracy 0.1879\nEpoch 6 Batch 400 Loss 5.0043 Accuracy 0.1899\nEpoch 6 Batch 500 Loss 4.9559 Accuracy 0.1921\nEpoch 6 Batch 600 Loss 4.9079 Accuracy 0.1944\nEpoch 6 Batch 700 Loss 4.8563 Accuracy 0.1970\nEpoch 6 Batch 800 Loss 4.8025 Accuracy 0.1998\nEpoch 6 Loss 4.7697 Accuracy 0.2014\nTime taken for 1 epoch: 134.85169196128845 secs\n\nEpoch 7 Batch 0 Loss 5.5210 Accuracy 0.2014\nEpoch 7 Batch 100 Loss 4.8345 Accuracy 0.2029\nEpoch 7 Batch 200 Loss 4.7371 Accuracy 0.2047\nEpoch 7 Batch 300 Loss 4.6617 Accuracy 0.2067\nEpoch 7 Batch 400 Loss 4.6266 Accuracy 0.2086\nEpoch 7 Batch 500 Loss 4.5782 Accuracy 0.2108\nEpoch 7 Batch 600 Loss 4.5335 Accuracy 0.2131\nEpoch 7 Batch 700 Loss 4.4864 Accuracy 0.2156\nEpoch 7 Batch 800 Loss 4.4360 Accuracy 0.2182\nEpoch 7 Loss 4.4074 Accuracy 0.2198\nTime taken for 1 epoch: 134.83391118049622 secs\n\nEpoch 8 Batch 0 Loss 5.2122 Accuracy 0.2198\nEpoch 8 Batch 100 Loss 4.5313 Accuracy 0.2213\nEpoch 8 Batch 200 Loss 4.4297 Accuracy 0.2230\nEpoch 8 Batch 300 Loss 4.3582 Accuracy 0.2250\nEpoch 8 Batch 400 Loss 4.3211 Accuracy 0.2269\nEpoch 8 Batch 500 Loss 4.2728 Accuracy 0.2291\nEpoch 8 Batch 600 Loss 4.2303 Accuracy 0.2313\nEpoch 8 Batch 700 Loss 4.1864 Accuracy 0.2337\nEpoch 8 Batch 800 Loss 4.1387 Accuracy 0.2362\nEpoch 8 Loss 4.1115 Accuracy 0.2377\nTime taken for 1 epoch: 135.38349986076355 secs\n\nEpoch 9 Batch 0 Loss 4.7978 Accuracy 0.2377\nEpoch 9 Batch 100 Loss 4.2679 Accuracy 0.2391\nEpoch 9 Batch 200 Loss 4.1719 Accuracy 0.2409\nEpoch 9 Batch 300 Loss 4.1051 Accuracy 0.2427\nEpoch 9 Batch 400 Loss 4.0719 Accuracy 0.2445\nEpoch 9 Batch 500 Loss 4.0220 Accuracy 0.2466\nEpoch 9 Batch 600 Loss 3.9820 Accuracy 0.2487\nEpoch 9 Batch 700 Loss 3.9377 Accuracy 0.2510\nEpoch 9 Batch 800 Loss 3.8928 Accuracy 0.2533\nEpoch 9 Loss 3.8658 Accuracy 0.2548\nTime taken for 1 epoch: 134.49065446853638 secs\n\nEpoch 10 Batch 0 Loss 4.6585 Accuracy 0.2548\nEpoch 10 Batch 100 Loss 4.0513 Accuracy 0.2562\nEpoch 10 Batch 200 Loss 3.9630 Accuracy 0.2578\nEpoch 10 Batch 300 Loss 3.8923 Accuracy 0.2596\nEpoch 10 Batch 400 Loss 3.8583 Accuracy 0.2614\nEpoch 10 Batch 500 Loss 3.8115 Accuracy 0.2633\nEpoch 10 Batch 600 Loss 3.7666 Accuracy 0.2654\nEpoch 10 Batch 700 Loss 3.7236 Accuracy 0.2675\nEpoch 10 Batch 800 Loss 3.6808 Accuracy 0.2697\nSaving checkpoint for epoch 10 at checkpoints/ckpt-2\nEpoch 10 Loss 3.6560 Accuracy 0.2711\nTime taken for 1 epoch: 135.33542895317078 secs\n\nEpoch 11 Batch 0 Loss 4.5336 Accuracy 0.2711\nEpoch 11 Batch 100 Loss 3.8740 Accuracy 0.2724\nEpoch 11 Batch 200 Loss 3.7798 Accuracy 0.2740\nEpoch 11 Batch 300 Loss 3.7140 Accuracy 0.2757\nEpoch 11 Batch 400 Loss 3.6744 Accuracy 0.2773\nEpoch 11 Batch 500 Loss 3.6284 Accuracy 0.2792\nEpoch 11 Batch 600 Loss 3.5844 Accuracy 0.2811\nEpoch 11 Batch 700 Loss 3.5431 Accuracy 0.2832\nEpoch 11 Batch 800 Loss 3.5023 Accuracy 0.2852\nEpoch 11 Loss 3.4781 Accuracy 0.2865\nTime taken for 1 epoch: 135.0199418067932 secs\n\nEpoch 12 Batch 0 Loss 4.1560 Accuracy 0.2865\nEpoch 12 Batch 100 Loss 3.7105 Accuracy 0.2878\nEpoch 12 Batch 200 Loss 3.6165 Accuracy 0.2893\nEpoch 12 Batch 300 Loss 3.5534 Accuracy 0.2908\nEpoch 12 Batch 400 Loss 3.5123 Accuracy 0.2924\nEpoch 12 Batch 500 Loss 3.4656 Accuracy 0.2942\nEpoch 12 Batch 600 Loss 3.4239 Accuracy 0.2960\nEpoch 12 Batch 700 Loss 3.3810 Accuracy 0.2980\nEpoch 12 Batch 800 Loss 3.3429 Accuracy 0.2999\nEpoch 12 Loss 3.3198 Accuracy 0.3011\nTime taken for 1 epoch: 135.1469693183899 secs\n\nEpoch 13 Batch 0 Loss 4.0652 Accuracy 0.3011\nEpoch 13 Batch 100 Loss 3.5588 Accuracy 0.3023\nEpoch 13 Batch 200 Loss 3.4785 Accuracy 0.3037\nEpoch 13 Batch 300 Loss 3.4116 Accuracy 0.3052\nEpoch 13 Batch 400 Loss 3.3776 Accuracy 0.3067\nEpoch 13 Batch 500 Loss 3.3288 Accuracy 0.3084\nEpoch 13 Batch 600 Loss 3.2871 Accuracy 0.3101\nEpoch 13 Batch 700 Loss 3.2482 Accuracy 0.3120\nEpoch 13 Batch 800 Loss 3.2126 Accuracy 0.3138\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate(input_article):\n    input_article = article_tokenizer.texts_to_sequences([input_article])\n    input_article = tf.keras.preprocessing.sequence.pad_sequences(input_article, maxlen=ENCODER_LEN, \n                                                                   padding='post', truncating='post')\n\n    encoder_input = tf.expand_dims(input_article[0], 0)\n\n    decoder_input = [summary_tokenizer.word_index['<sos>']]\n    output = tf.expand_dims(decoder_input, 0)\n    \n    for i in range(DECODER_LEN):\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n\n        predictions, attention_weights = transformer(\n            encoder_input, \n            output,\n            False,\n            enc_padding_mask,\n            combined_mask,\n            dec_padding_mask\n        )\n\n        predictions = predictions[: ,-1:, :]\n        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n\n        if predicted_id == summary_tokenizer.word_index['<eos>']:\n            return tf.squeeze(output, axis=0), attention_weights\n\n        output = tf.concat([output, predicted_id], axis=-1)\n\n    return tf.squeeze(output, axis=0), attention_weights","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize(input_article):\n    summarized = evaluate(input_article=input_article)[0].numpy()\n    summarized = np.expand_dims(summarized[1:], 0)  \n    return summary_tokenizer.sequences_to_texts(summarized)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions\n\nBelow me make predictions on some texts to see how the model is performimg. Since this was a very basic approach the model wont perform that well but it can surely be improved.","metadata":{}},{"cell_type":"code","source":"article[5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Real Headline : \", summary[5][5:-5],\"\\n Predicted Summary : \", summarize(article[5]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article[16]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Real Headline : \", summary[16][5:-5],\"\\nPredicted Summary : \", summarize(article[16]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article[23]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Real Headline : \", summary[23][5:-5],\"\\nPredicted Summary : \", summarize(article[23]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}